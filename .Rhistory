carEvaluation <- read.table("car.data", sep=",")
View(carEvaluation)
colnames(carEvaluation) <- c('preçoCompra', 'preçoManutenção', 'portas', 'ocupantes', 'mala', 'segurança', 'classe')
library('caret')
install.packages('caret', dependencies = T)
library('caret')
particaoCar = createDataPartition(1:nrow(carEvaluation),p=.7)
treinoCar = carEvaluation[particaoCar$Resample1,]
testeCar = carEvaluation[- particaoCar$Resample1,]
library(bnlearn)
library(e1071)
library(caret)
library(e1071)
library(caret)
carNaiveBayes = naiveBayes(classe ~., treinoCar) # criar Modelo
carNaiveBayes # retorno das probabilidades do modelo
View(carEvaluation)
View(carEvaluation)
View(carEvaluation)
View(carEvaluation)
View(carEvaluation)
carNaiveBayes # retorno das probabilidades do modelo
previsaoNBCar  = predict(carNaiveBayes, testeCar)
confusionMatrix(previsaoNBCar, testeCar$classe)
carEvaluation <- read.table("car.data", sep=",")
View(carEvaluation)
colnames(carEvaluation) <- c('preçoCompra', 'preçoManutenção', 'portas', 'ocupantes', 'mala', 'segurança', 'classe')
library(caret)
particaoCar = createDataPartition(1:nrow(carEvaluation),p=.7)
particaoCar
testeCar = carEvaluation[- particaoCar$Resample1,]
library(bnlearn)
library(e1071)
library(caret)
install.packages('bnlearn', dependencies = T)
library(bnlearn)
carNaiveBayes = naiveBayes(classe ~., treinoCar)
particaoCar = createDataPartition(1:nrow(carEvaluation),p=.7)
treinoCar = carEvaluation[particaoCar$Resample1,]
testeCar = carEvaluation[- particaoCar$Resample1,]
carNaiveBayes = naiveBayes(classe ~., treinoCar)
carNaiveBayes
previsaoNBCar  = predict(carNaiveBayes, testeCar)
confusionMatrix(previsaoNBCar, testeCar$classe)
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d2=read.table("student-por.csv",sep=";",header=TRUE)
studentsPerformance=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
View(studentsPerformance)
particaoStudents = createDataPartition(1:nrow(studentsPerformance),p=.7)
treinoStudents = studentsPerformance[particaoCar$Resample1,]
testeStudents = studentsPerformance[- particaoCar$Resample1,]
library(GA)
library(mgcv)
library(Metrics)
install.packages('GA', dependencies = T)
install.packages('Metrics', dependencies = T)
library(GA)
library(mgcv)
library(Metrics)
studentsPerformanceInt <- studentsPerformance[,c(3,7,8,15:17,24:33,35:37,44:53)]
str(studentsPerformanceInt)
studentsPerformanceOLS <- studentsPerformanceInt[,c(4:6,10:11,14:16)]
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
oiopasdasd
asd
asd
asd
ada
sdasd
asd
library(bnlearn)
library(e1071)
library(caret)
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
particaoCar = createDataPartition(1:nrow(carEvaluation),p=.7)
treinoCar = carEvaluation[particaoCar$Resample1,]
testeCar = carEvaluation[- particaoCar$Resample1,]
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d2=read.table("student-por.csv",sep=";",header=TRUE)
studentsPerformance=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
particaoStudents = createDataPartition(1:nrow(studentsPerformance),p=.7)
treinoStudents = studentsPerformance[particaoCar$Resample1,]
testeStudents = studentsPerformance[- particaoCar$Resample1,]
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
View(OLS)
studentsPerformanceInt <- studentsPerformance[,c(3,7,8,15:17,24:33,35:37,44:53)]
str(studentsPerformanceInt)
studentsPerformanceOLS <- studentsPerformanceInt[,c(4:6,10:11,14:16)]
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
summary(ga.OLS)
# Usa a base Students Performance #
# carregar pacotes de Algoritmos Genéticos
library(GA)
library(mgcv)
library(Metrics)
# Uma vez que usaremos os algoritmos genéticos para regressão, é necessário deixar apenas as colunas numéricas
studentsPerformanceInt <- studentsPerformance[,c(3,7,8,15:17,24:33,35:37,44:53)]
str(studentsPerformanceInt)
# Para fins didáticos (deixar a função mais simples), faremos um corte na base, selecionando apenas alguns atributos
studentsPerformanceOLS <- studentsPerformanceInt[,c(4:6,10:11,14:16)]
# Criar função objetivo que o algoritmo genético buscará aprender
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
# realizar a regressão com algoritmos genéticos
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
#### gráficos e sumários da regressão com Algoritmos Genéticos
plot(ga.OLS)
summary(ga.OLS)
predicoesGAOLS <- rep(0, nrow(studentsPerformanceOLS)) # Criar vetor vazio para colocar as predições
# laço para gerar as predições de forma iterativa
for(i in 1:nrow(studentsPerformanceOLS)) { # laço maior = linhas
for(j in 1:7) { # laço menor = colunas
predicoesGAOLS[i] <-  predicoesGAOLS[i] + ga.OLS@solution[j+1]*studentsPerformanceOLS[i,j]
}} # preencher o vetor de predições com o valor dele mesmo mais o peso + valor original da variável
predicoesGAOLS <- predicoesGAOLS+ga.OLS@solution[1] # reduzir o intercepto
rmse(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro-médio
rrse(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro relativo
# código da predição sem laço #
# predicoesGAOLS <-
#   ga.OLS@solution[1]+
#   ga.OLS@solution[2]*studentsPerformanceOLS[,1]+
#   ga.OLS@solution[3]*studentsPerformanceOLS[,2]+
#   ga.OLS@solution[4]*studentsPerformanceOLS[,3]+
#   ga.OLS@solution[5]*studentsPerformanceOLS[,4]+
#   ga.OLS@solution[6]*studentsPerformanceOLS[,5]+
#   ga.OLS@solution[7]*studentsPerformanceOLS[,6]+
#   ga.OLS@solution[8]*studentsPerformanceOLS[,7]
#### Car Evaluation ####
# Entrada Car Evaluation
carEvaluation <- read.table("car.data", sep=",")
colnames(carEvaluation) <- c('preçoCompra', 'preçoManutenção', 'portas', 'ocupantes', 'mala', 'segurança', 'classe')
# Partição Car Evaluation
particaoCar = createDataPartition(1:nrow(carEvaluation),p=.7)
treinoCar = carEvaluation[particaoCar$Resample1,]
testeCar = carEvaluation[- particaoCar$Resample1,]
# Saída Car Evaluation
write.csv(carEvaluation, file = "carEvaluation.csv")
#### Student Performance ####
# Entrada Student Performance
d1=read.table("student-mat.csv",sep=";",header=TRUE)
d2=read.table("student-por.csv",sep=";",header=TRUE)
studentsPerformance=merge(d1,d2,by=c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet"))
particaoStudents = createDataPartition(1:nrow(studentsPerformance),p=.7)
treinoStudents = studentsPerformance[particaoCar$Resample1,]
testeStudents = studentsPerformance[- particaoCar$Resample1,]
# Saída Student Performance
write.csv(studentsPerformance, file = "studentsPerformance.csv")
library(GA)
library(mgcv)
library(Metrics)
# Uma vez que usaremos os algoritmos genéticos para regressão, é necessário deixar apenas as colunas numéricas
studentsPerformanceInt <- studentsPerformance[,c(3,7,8,15:17,24:33,35:37,44:53)]
str(studentsPerformanceInt)
# Para fins didáticos (deixar a função mais simples), faremos um corte na base, selecionando apenas alguns atributos
studentsPerformanceOLS <- studentsPerformanceInt[,c(4:6,10:11,14:16)]
# Criar função objetivo que o algoritmo genético buscará aprender
OLS <- function(data, b0, b1, b2, b3, b4, b5, b6, b7){
attach(data, warn.conflicts=F)
#passar como parâmetros as variáveis que serão usadas na predição
Y_hat <- b0  + b1*traveltime.x + b2*studytime.x + b3*failures.x + b4*Dalc.x + b5*Walc.x + b6*G1.x + b7*G2.x
#passar a variável de saída
SSE = t(G3.x-Y_hat) %*% (G3.x-Y_hat) #matrix formulation for SSE
detach(data)
return(SSE)
}
# realizar a regressão com algoritmos genéticos
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
#### gráficos e sumários da regressão com Algoritmos Genéticos
plot(ga.OLS)
summary(ga.OLS)
predicoesGAOLS <- rep(0, nrow(studentsPerformanceOLS)) # Criar vetor vazio para colocar as predições
# laço para gerar as predições de forma iterativa
for(i in 1:nrow(studentsPerformanceOLS)) { # laço maior = linhas
for(j in 1:7) { # laço menor = colunas
predicoesGAOLS[i] <-  predicoesGAOLS[i] + ga.OLS@solution[j+1]*studentsPerformanceOLS[i,j]
}} # preencher o vetor de predições com o valor dele mesmo mais o peso + valor original da variável
predicoesGAOLS <- predicoesGAOLS+ga.OLS@solution[1] # reduzir o intercepto
rmse(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro-médio
rrse(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro relativo
# código da predição sem laço #
# predicoesGAOLS <-
#   ga.OLS@solution[1]+
#   ga.OLS@solution[2]*studentsPerformanceOLS[,1]+
#   ga.OLS@solution[3]*studentsPerformanceOLS[,2]+
#   ga.OLS@solution[4]*studentsPerformanceOLS[,3]+
#   ga.OLS@solution[5]*studentsPerformanceOLS[,4]+
#   ga.OLS@solution[6]*studentsPerformanceOLS[,5]+
#   ga.OLS@solution[7]*studentsPerformanceOLS[,6]+
#   ga.OLS@solution[8]*studentsPerformanceOLS[,7]
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=5,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
plot(ga.OLS)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(- 0.1, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(0.1, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=5,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
plot(ga.OLS)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(- 0.1, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(0.1, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=100,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
plot(ga.OLS)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(- 0.1, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(0.1, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(- 0.5, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(0.5, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(- 0.05, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(0.05, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
plot(ga.OLS)
start_time <- Sys.time()
ga.OLS <- ga(type='real-valued',
min=rep(-100, ncol(studentsPerformanceOLS)), #colocar valor mínimo de cada parâmetro (n(x) + 1)
max=rep(100, ncol(studentsPerformanceOLS)), #colocar valor máximo de cada parâmetro (n(x) + 1)
popSize=500,
maxiter=500,
names=c('intercepto', 'traveltime', 'studytime', 'failures', 'Dalc', 'Walc', 'G1', 'G2'), # nomes das variáveis
keepBest=T, fitness = function(b)-OLS(studentsPerformanceOLS, b[1],b[2], b[3], b[4], b[5], b[6], b[7], b[8])) # lembrar de colocar o total de parâmetros n(x)+1
end_time <- Sys.time()
print(total_time <- end_time - start_time)
plot(ga.OLS)
predicoesGAOLS <- rep(0, nrow(studentsPerformanceOLS))
for(i in 1:nrow(studentsPerformanceOLS)) { # laço maior = linhas
for(j in 1:7) { # laço menor = colunas
predicoesGAOLS[i] <-  predicoesGAOLS[i] + ga.OLS@solution[j+1]*studentsPerformanceOLS[i,j]
}}
for(i in 1:nrow(studentsPerformanceOLS)) { # laço maior = linhas
for(j in 1:7) { # laço menor = colunas
predicoesGAOLS[i] <-  predicoesGAOLS[i] + ga.OLS@solution[j+1]*studentsPerformanceOLS[i,j]
}} # preencher o vetor de predições com o valor dele mesmo mais o peso + valor original da variável
predicoesGAOLS <- predicoesGAOLS+ga.OLS@solution[1]
rmse(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro-médio
rrse(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro relativo
plot(ga.OLS)
plot(studentsPerformanceOLS$G3.x, predicoesGAOLS) # Raiz quadrada do erro-médio
plot(studentsPerformanceOLS$G3.x, predicoesGAOLS)
plot(studentsPerformanceOLS$G3.x, predicoesGAOLS)
require(rpart)
require(rpart.plot)
require(party)
require(partykit)
require(tree)
library(caret)
carCtree <- ctree(classe ~., treinoCar)
# Partição Car Evaluation
particaoCar = createDataPartition(1:nrow(carEvaluation),p=.7)
treinoCar = carEvaluation[particaoCar$Resample1,]
testeCar = carEvaluation[- particaoCar$Resample1,]
carCtree <- ctree(classe ~., treinoCar)
plot(carCtree, type="simple", gp = gpar(fontsize = 6))
previsaoCtreeCar = predict(carCtree, testeCar)
previsaoCtreeCar = predict(carCtree, testeCar)
previsaoCtreeCar = as.data.frame(previsaoCtreeCar)
confusionMatrix(previsaoCtreeCar$previsaoCtreeCar, testeCar$classe)
carRpart <- rpart(classe ~., treinoCar)
rpart.plot(carRpart)
require(rpart.plot)
install.packages('rpart.plot', dependencies = T)
require(rpart.plot)
rpart.plot(carRpart)
plotcp(carRpart)
carRpart <- prune(carRpart, cp=0.059)
rpart.plot(carRpart, extra = 104, branch.lty = 2,
nn= T, tweak = 1.2)
previsaoPartCar = predict(carRpart, testeCar, type = "class") # realizar predição # parâmetro type = "class" é para retornar o resultado com mairo probabilidade de ocorrer
previsaoPartCar = as.data.frame(previsaoPartCar) # transformar predições em data frame
confusionMatrix(previsaoPartCar$previsaoPartCar, testeCar$classe) # matriz de confusão
library(class)
library(caret)
library(ade4)
treinoCarDummy <- acm.disjonctif(carEvaluation[,1:6])
View(treinoCarDummy)
View(treinoCarDummy)
View(treinoCarDummy)
View(treinoCarDummy)
treinoCarDummy$classe <- carEvaluation$classe
View(treinoCarDummy)
View(treinoCarDummy)
testeCarDummy <- treinoCarDummy[c(10:20),] # como o Knn lida com novos casos, vamos criar treino e teste retirando algumas linhas da base de treino
treinoCarDummy <- treinoCarDummy[-c(10:20),] # as linhas escolhidas para a base de teste são retiradas da base de treino
carKnn = knn(treinoCarDummy[,1:21], testeCarDummy[,1:21], treinoCarDummy[,22], k=20) # criamos o modelo, indicando quantos vizinhos serão pesquisados (k)
carKnn
carKnn = knn(treinoCarDummy[,1:21], testeCarDummy[,1:21], treinoCarDummy[,22], k=20)
carKnn
confusionMatrix(carKnn, testeCarDummy$classe)
carKnn = knn(treinoCarDummy[,1:21], testeCarDummy[,1:21], treinoCarDummy[,22], k=1)
confusionMatrix(carKnn, testeCarDummy$classe)
carKnn = knn(treinoCarDummy[,1:21], testeCarDummy[,1:21], treinoCarDummy[,22], k=20)
confusionMatrix(carKnn, testeCarDummy$classe)
carKnn = knn(treinoCarDummy[,1:21], testeCarDummy[,1:21], treinoCarDummy[,22], k=100)
confusionMatrix(carKnn, testeCarDummy$classe)
library(e1071)
treinoCarDummy <- acm.disjonctif(treinoCar[,1:6])
treinoCarDummy$classe <- treinoCar[,7]
View(treinoCarDummy)
testeCarDummy <- acm.disjonctif(testeCar[,1:6])
testeCarDummy$classe <- testeCar[,7]
svmCar = svm(classe ~ ., data = treinoCarDummy, cost = 10, scale = FALSE)
View(svmCar)
svmCar
plot(svmCar, treinoCarDummy, segurança.high ~ preçoCompra.low)
plot(svmCar, treinoCarDummy, segurança.medio ~ preçoCompra.low)
plot(svmCar, treinoCarDummy, segurança.midle ~ preçoCompra.low)
plot(svmCar, treinoCarDummy, segurança.med ~ preçoCompra.high)
previsaoSVMCar <- predict(svmCar, testeCarDummy) # criar predição
confusionMatrix(previsaoSVMCar, testeCarDummy$classe) # matriz de confusão
